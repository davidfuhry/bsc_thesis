\section{Theorie}

% Forschungsstand, Methoden zur Identifizierung

\subsection{Stand der Forschung}

Das Erscheinen von Richard \textcite{hofstadter_2008} Essay \textit{The Paranoid Style in American Politics} wird heute üblicherweise als der Beginn der wissenschaftlichen Auseinandersetzung mit Verschwörungstheorien gesehen.
In seiner Arbeit setzt Hofstadter sich mit dem Einfluss von Verschwörungstheorien und Verschwörungsrhetorik (dem \textit{Paranoid Style}) auf die US Amerikanische Politik, wie etwa die Schriften von Senator McCarthy und die nach ihm benannte Praxis des McCarthyismus, auseinander.

Das weitere Forschungsinteresse im restlichen 20. Jahrhundert war nur gering, die verbleibende Forschung fiel meist in eine von Zwei Kategorien, wie \textcite{sunstein_2008} passend zusammenfassen:

\begin{quotation}
    The academic literature on conspiracy theories is thin, and most of it falls into one 
    of two classes: (1) work by analytic philosophers, especially in epistemology and the 
    philosophy of science, that asks what counts as a “conspiracy theory” and whether such theories are methodologically suspect; (2) a smattering of work in sociology and Freudian psychology on the causes of conspiracy theorizing. \parencite[][2]{sunstein_2008}
\end{quotation}

In der jüngeren Vergangenheit haben vor allem Drei Entwicklungen Verschwörungstheorien und damit auch der Forschung in diesem Bereich vorschub geleistet.

Dies war zum einen die Verbreitung des Internets um die Jahrtausendwende.
Die Mehrheit der Autor:innen sieht darin ein erhebliches Hilfsmittel für die Verbreitung von Verschwörungstheorien, so schreibt etwa \textcite{stano_2020}: "[...] The Internet, and in particular social networks, have proved fundamental to the spread and development of such [conspiracy] theories" \parencite[][492]{stano_2020}.\footnote{Es gilt jedoch anzumerken, dass auch die gegenteile Auffassung in der Literatur vertreten ist, etwa bei \textcite{clarke_2007}.}

In der jüngsten Vergangenheit haben dann insbesondere die Wahl Donald Trumps zum US-Präsidenten 2016 und die aktuelle COVID-19 Pandemie Verschwörungstheorien ins Zentrum des öffentlichen Interesse gerückt.
Wärend die wissenschaftliche Aufarbeitung insbesondere von letzterer noch am Anfang steht, sind im Zuge dieser Entwicklungen bereits erste Arbeiten entstanden, die neue Ansätze zeigen, wie etwa die von \textcite{shahsavari_2020}.

Eines der Kernprobleme in der Arbeit mit Verschwörungstheorien, ist es diese verlässlich als solche zu identifizieren.
Dies hat nicht nur eine fundamentale Rolle für theoretische Arbeiten, sondern ist auch von immenser praktischer Relevanz, in einer Zeit in der in sozialen Medien die Grenzen zwischen Nachrichten, Verschwörungstheorien und Fake-News immer schwerer auszumachen sind.

In der Vergangenheit war die wissenschaftliche Beantwortung dieser Frage meist eng mit der Frage danach verbunden, was eine Verschwörungstheorie ausmacht und anhand welcher Kriterien sich dies bestimmen lässt.
Eine beispielhafte Arbeit ist hier \textcite{uscinski_2014}.
Die Autoren nutzen darin 6 verschiedene Tests um Verschwörungstheorien zu identifizieren. Als Beispiel sei Occamm`s Razor, also die Frage nach der einfachsten Erklärung, und die falsifizierbarkeit einer Theorie genannt.
Die Autoren selbst werten mit diesen Kriterien und der Methode der Inhaltsanalyse sowie einer Vielzahl von studentischen Kodierer:Innen einen Korpus an Briefen an US-Redaktionen aus \parencite[54ff]{uscinski_2014}.
Während die Autoren überzeugend dafür argumentieren, alle der aufgestellten Kriterien für eine Klassifizerung einzusetzten \parencite[52f]{uscinski_2014}, ist keines der eingeführten Kriterien, zumindest mit den aktuellen technischen Möglichkeiten, wirklich geeignet um automatisierte Klassifikationen vorzunehmen.

In der jüngeren Vergangenheit sind demgegenüber aber auch erste Arbeiten entstanden, die sich mit automatisieren Verfahren rund um Verschwörungstheorien beschäftigen.
Eine solche Arbeit ist die von \textcite{samory_2018}, in der die Autor:innen automatisiert Triplets bestehend aus \textit{agent}, \textit{action} und \textit{target} aus verschwörungstheoretischen Online Beiträgen extrahieren.
Als Datengrundlage nutzen sie dazu Beiträge aus dem Reddit Subforum r/conspiracy.
Diese werten sie mittels einer NLP Pipeline aus, die unter anderem Topic Modeling, Dependency Parser und Wordvektoren nutzt, aber auch vereinzelt Expertenwissen einbringt \parencite[][6ff]{samory_2018}.
Der Ansatz stellt einen wichtigen Beitrag zu einer vollständig automatisierten Analyse dar, ist aber auch verhältnismäßig komplex und basiert auf einer Datenbasis die nicht notwendigerweise Repräsentativ für "wild" vertretene Verschwörungstheorien ist,\footnote{Das r/conspiracy Forum dient explizit zum austausch von und über solche Theorien. Allein diese Selbstidentifikation als Verschwörugnsthoeretiker:in ist in der Szene eher unüblich, beansprucht man doch die "echte" Wahrheit zu verbrieten.} so dass die Übertragbarkeit auf andere Datensätze/Anwendungsfälle zumindest nicht unproblematisch sein dürfte.

Eine weitere Arbeit die sich mit automatisierten Auswertungen beschäftigt, ist die von \textcite{shahsavari_2020}.
Die Autor:innen werten dabei Online Diskussionen in Foren wie Reddit und 4Chan aus, die sich mit der Covid 19 Pandemie beschäftigen.
Die Auswahl ob Diskussionen verschwörungstheoretische Inhalte enthalten und somit ausgewertet werden, wurde dabei von einem Expertengremium getroffen \parencite[284f]{shahsavari_2020}.
Es werden mittels Methoden aus der Natürlichen Sprachverarbeitung narrative Netzwerke ausgewertet und so Verbindungen zu den inhalten von Nachrichten und den aktuell "beliebtesten" Verschwörungstheorien aufgezeigt.

Näher an der Problemstellung dieser Arbeit ist die Methode die von \textcite{potthast_2018} vorgestellt wird.
Darin stellen die Autoren Methodik vor um mittels Machine Learning Verfahren und stilistischen Features Fake-News und politisch extreme Artikel zu identifizieren.
Sie greifen dabei auf einen von professionellen Journalisten kategoriesierten Korpus zurück und können extremistische Artikel aufgrund dieser Merkmale von anderen unterscheiden.
Da Verschwörungstheorien eine große Schnittmenge mit Fake-News und politischen Extremen (insbesondere der rechtsextremistischen Szene) haben, wird es von Interesse sein, zu sehen ob die in dieser Arbeit vorgestellten Methoden auf Verschwörungstheoretischen Texten ähnliche Ergebnisse liefern.

\subsection{Merkmale von verschwörungstheoretischen Texten}

Um Verschwörungstheorien zuverlässig zu identifizieren, soll zunächst ein Blick in die Literatur erfolgen und in die in der qualitativen und quantitativen Forschung gemachten Beobachtungen zu sprachlichen Merkmalen von Verschwörungstheorien.
Eine erschöpfende Auflistung aller in der Literatur zu findenden sprachlichen Merkmale von Verschwörungstheorien ist insbesondere mit dem erstarkten Forschungsinteresse in der jüngsten Vergangenheit kaum möglich noch wäre es zielführend.
Es sollen daher hier vor allem solche Merkmale genannt werden, die sich für eine quantitative, automatisierte Erfassung eignen und in dieser Arbeit angewandt werden.

Eine in der Literatur häufig gemachte Beobachtung ist die Emotionalität der Argumentation in Verschwörungstheorien \parencite[Vgl.][10]{miller_2002}.
Dieses Argument findet sich auch bei \textcite[][93ff]{butter_2018}, der noch spezifischer darauf eingeht, dass es vor allem die vermeintlichen Verschwörer sind denen mit "metaphorisch aufgeladener, bisweilen apokalyptischer Sprache ausschließlich negative Eigenschaften zugeschrieben [werden]" \parencite[][93f]{butter_2018}.

Während die emotionalität spezifischer Aspekte der Argumentation eine häufig gemachte Beobachtung ist, steht dazu im Gegensatz die Beobachtung über den allgemeinen Stil der Verschwörungstheoretiker:innen.
So spricht ebenfalls \textcite[][61]{butter_2018} davon, dass sich Verschwörungstheoretiker traditionell um eine seriöse Darstellung bemühen und sich der verwendete Stil an dem der Wissenschaft anlehne.
Diese Feststellung findet sich bereits bei \textcite{hofstadter_2008}:

\begin{quotation}
    The higher paranoid scholarship is nothing if not coherent—in fact the paranoid mind is far more coherent than the real world. It is nothing if not scholarly in technique. McCarthy’s 96-page pamphlet, McCarthyism, contains no less than 313 footnote references, and Mr. Welch’s incredible assault on Eisenhower, The Politician, has one hundred pages of bibliography and notes. \parencite[][37]{hofstadter_2008}
\end{quotation}

Seit der Erstveröffentlichung von Hofstadters Aufsatz hat vor allem die Existenz des Internets zu Veränderungen in der Erzählart von Verschwörungstheorien geführt.
Die Obsession an Belegen und Referenzen existiert zwar weiterhin, hat sich aber insoweit Verändert, als das nicht mehr unbedingt Fussnoten das Mittel der Wahl sind, vielmehr wird sich der Mittel des Internets bedient, Inhalte werden direkt eingebunden oder verlinkt.
So schreibt etwa \textcite{soukup_2008} der sich spezifisch mit Verschwörungstheorien um den 11. September im Internet befasst, diese müssten als "digital, hypertextual, and multimedial experience" \parencite[10]{soukup_2008} verstanden werden.

Erst in der jüngeren Vergangenheit finden sich Arbeiten die sich spezifisch mit den linguistischen Merkmalen von Verschwörungstheorien auseinandersetzen.
\textcite{schafer_2018} etwa analysiert einen Korpus aus Kommentaren zu verschwörungstheoretischen YouTube-Videos.
Sie stellt dabei unter anderem eine gehäufte Verwendung von Ironie und \textit{scare quotes} fest, wenn es darum geht die Gegenseite negativ darzustellen \parencite[235]{schafer_2018}.
Ähnlich der bereits erörterten Literatur findet die Autorin auch eine hohe Dichte von Belegen und Referenzen die die Kompetenzen der Verschwörungstheoretiker:innen unterstreichen sollen, stellt aber zusätzlich heraus, dass diese sich häufig in Form von Nennungen von Namen und Zahlenangaben ausdrücken \parencite[234]{schafer_2018}.

Eine ähnliche Beobachtung macht auch \textcite{filatkina_2018}, die feststellt:

\begin{quotation}
    In einem Beitrag oft mehrfach angeführte Verweise auf offizielle Zahlen [...] bzw. das wörtliche Zitieren der VertreterInnen der Wissenschaft und Politik sollen die Glaubwürdigkeit herstellen. \parencite[][208]{filatkina_2018}
\end{quotation}

Ebenfalls nennt die Autorin eine übliche Konstruktion in der durch offene und geschlossene Fragen die Aufmerksamkeit der Leser:innen auf bestimmte Aspekte gelenkt werden soll \parencite[][205]{filatkina_2018}.
Als letztes stilistisches Merkmal sei hier noch die häufige Nutzung von Negationswörtern genannt, wie sie etwa von \textcite[149]{stumpf_2019} beobachtet wird.

% Vokabular:
%  - Entlarfungsvokabular \parencite[][51]{ebling_2013}
%  - Stumpf/Römer 2019 haben viel Vokabular

\subsection{Textklassifizierung}

Die Aufgabe das so gesammelte Wissen zu operationalisieren fällt in den Bereich der Textklassifizierung bzw. -kategorisierung.
Dieses Feld geht auf \textcite{maron_1961} zurück, der Dokumente aufgrund sogenannter \textit{clue words} und einem probabilistischen Ansatz Kategorien zuordnete und dabei schon viele Methoden die in modernen Verfahren genutzt werden, wie etwa das Filtern von Stopwörtern, implementierte.

Das Problem lässt sich grundlegend Formalisieren als die Suche nach einer Funktion $F$ mit $F : D \times C \rightarrow {0, 1}$.
Es wird also eine Funktion gesucht, die alle Dokumente $D$ jeder Kategorie $C$ entweder positiv oder negativ zuordnet \parencite[vgl.][66f]{feldman_sanger_2006}.
Im hier vorliegenden Fall ist nur eine Kategorie gesucht, so dass es sich um ein binäres Klassifiezierungsproblem handelt.
Da komplette Textdateien für Computer nur sehr bedingt zu Verarbeiten sind, werden die Dokumente $D$ durch sogenannte Feature Vektoren repräsentiert.

Die Erstellung dieser Vektoren ist der wesentliche Schritt um eine gute Klassifizierungsleistung zu erhalten.
Vermutlich am häufigsten als Repräsentation genutzt werden Wortfrequenzen, meist in der Form term-frequency reverse-document-frequency (\textit{tf-idf}), ein Wert der Ausdrücken soll wie wichtig ein Wort für ein spezifisches Dokument ist, indem er die Häufigkeit des Auftauchens in einem Dokument ins Verhältnis zur Häufigkeit des Vorkommens in allen Dokumenten setzt.
Entscheidend ist auch welche Wörter als Features genutzt werden, während es häufig ausreicht die Häufigsten n-Prozent der Wörter\footnote{Nachdem Wörter ohne Informationswert wie etwa Stopwörter  gefiltert wurden}  zu nutzen \parencite[][68]{feldman_sanger_2006}, gibt es hier eine Vielzahl von komplexeren und spezialisierten Verfahren.
Für einen Überblick über solche sei auf die entsprechende Literatur verwiesen, etwa \textcite{yang_1997}.

Neben reinen Wortfrequenzen sind für diese Arbeit auch Part of Speech Tags relevant.
Diese Annotationen der Wortarten werden zum Teil für Textklassifikation benutzt, sind aber insbesondere für stilistische Fragestellungen von Relevanz \parencite[siehe etwa][]{jimenez_2020}.
Da in dieser Arbeit, in Anlehnung an Hoffstadter, der Paranoide Stil Untersuchungsgegenstand ist, sind solche Elemente vielversprechend.